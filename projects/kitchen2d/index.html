<meta charset="utf-8">
<title>Active model learning and diverse action sampling for task and motion planning</title>
<link rel="stylesheet" type="text/css" href="style-index.css" />
<h1>Active model learning and diverse action sampling for task and motion planning</h1>
<p>
<a href="http://zi-wang.com">Zi Wang</a>, <a href="http://web.mit.edu/caelan/www/">Caelan Reed Garrett</a>, <a href="http://people.csail.mit.edu/lpk/">Leslie Pack Kaelbling</a>, <a href="http://people.csail.mit.edu/tlp/">Tomás Lozano-Pérez</a>
</p>
<p>
<a href="http://www.csail.mit.edu">MIT CSAIL</a>
</p>
{ziw, caelan, lpk, tlp}@csail.mit.edu
</p>
<h2>Abstract</h2>
<p>
The objective of this work is to augment the basic abilities of a robot by learning to use new sensorimotor primitives to enable the solution of complex long-horizon problems. Solving long-horizon problems in complex domains requires flexible generative planning that can combine primitive abilities in novel combinations to solve problems as they arise in the world.  In order to plan to combine primitive actions, we must have models of the preconditions and effects of those actions: under what circumstances will executing this primitive achieve some particular effect in the world?

We use, and develop novel improvements on, state-of-the-art methods for active learning and sampling.  We use Gaussian process methods for learning the conditions of operator effectiveness from small numbers of expensive training examples collected by experimentation on a robot. We develop adaptive sampling methods for generating diverse elements of continuous sets (such as robot configurations and object poses) during planning for solving a new task, so that planning is as efficient as possible. We demonstrate these methods in an integrated system, combining newly learned models with an efficient continuous-space robot task and motion planner to learn to solve long horizon problems more efficiently than was previously possible.

</p>
<h2>Full text</h2>
<p>
<a href="http://zi-wang.com/pub/kitchen2d.pdf">download here</a>
</p>

<h2>Code</h2>
<p>
<a href="https://github.com/zi-w/Kitchen2D">download here</a>
</p>

<h2>Video</h2>
<iframe width="560" height="315" src="https://www.youtube.com/embed/QWjLYjN8axg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

<iframe width="560" height="315" src="https://www.youtube.com/embed/q3YPH_b7iR0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

<iframe width="560" height="315" src="https://www.youtube.com/embed/b5s8Ph5P9ps" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

<h2>Approximate BibTex Entry</h2>

<p class="bibtex">@article{wang2018active,
    <br>&nbsp;&nbsp;&nbsp;&nbsp;title = {Active model learning and diverse action sampling for task and motion planning},
    <br>&nbsp;&nbsp;&nbsp;&nbsp;author = {Wang, Zi and Garrett, Caelan Reed and Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
    <br>&nbsp;&nbsp;&nbsp;&nbsp;journal={arXiv preprint arXiv:1803.00967},
    <br>&nbsp;&nbsp;&nbsp;&nbsp;year = {2018}}</p>



<footer>
<aside>Mar 2, 2018</aside>
</footer>
